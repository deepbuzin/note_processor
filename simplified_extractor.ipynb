{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Note Extraction ðŸ¦œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dotenv\n",
    "\n",
    "dotenv.load_dotenv(dotenv.find_dotenv())\n",
    "\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.documents import Document\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "from pathlib import Path\n",
    "import yaml\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from typing import Dict, Optional\n",
    "\n",
    "random.seed(1337)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and parse notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VAULT_PATH = Path(\"../obsidian\").resolve()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert VAULT_PATH.exists()\n",
    "\n",
    "note_paths = list(VAULT_PATH.rglob(\"*.md\"))\n",
    "print(f\"Found {len(note_paths)} notes in the vault\")\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-4o\",\n",
    "    temperature=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Note(BaseModel):\n",
    "    name: str\n",
    "    frontmatter: Optional[Dict]\n",
    "    body: str\n",
    "    relative_path: str\n",
    "\n",
    "    @classmethod\n",
    "    def from_path(cls, path: Path) -> \"Note\":\n",
    "        with path.open(\"r\") as f:\n",
    "            lines = f.readlines()\n",
    "\n",
    "            if lines and lines[0].strip() == \"---\":\n",
    "                frontmatter_lines = []\n",
    "                for line in lines[1:]:\n",
    "                    if line.strip() == \"---\":\n",
    "                        break\n",
    "                    frontmatter_lines.append(line)\n",
    "\n",
    "                if frontmatter_lines:\n",
    "                    frontmatter_content = \"\".join(frontmatter_lines)\n",
    "                    frontmatter = yaml.safe_load(frontmatter_content)\n",
    "\n",
    "                    if len(lines) > len(frontmatter_lines) + 2:\n",
    "                        lines = lines[len(frontmatter_lines) + 2:]\n",
    "                    else:\n",
    "                        lines = []\n",
    "            else:\n",
    "                frontmatter = None\n",
    "\n",
    "            body = \"\".join(lines)\n",
    "\n",
    "        return cls(\n",
    "            name=path.stem,\n",
    "            frontmatter=frontmatter,\n",
    "            body=body,\n",
    "            relative_path=path.relative_to(VAULT_PATH).as_posix(),\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "notes = [Note.from_path(note_path) for note_path in note_paths]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract categories and summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "persist_path = Path(\"notes_with_categories\")\n",
    "\n",
    "note_categories = {\n",
    "    \"Article Draft\": \"Draft of an article I've been writing for my newsletter. Contains some original writing.\",\n",
    "    \"Call Note\": \"Notes taken from the meeting I've had. Has mentions of agenda and-or feedback.\",\n",
    "    \"Diary Entry\": \"Note that contains musings about my feelings, emotions, events that happened in my life, reflections etc.\",\n",
    "    \"General Note\": \"Any note that doesn't fit in other categories.\",\n",
    "    \"Paper Highlights\": \"Highlights from a scientific paper I read. Usually refers to AI or computer vision.\",\n",
    "}\n",
    "\n",
    "category_prompt = \"\\n\".join(\n",
    "    [f\"- {name}: {description}\" for name, description in note_categories.items()]\n",
    ")\n",
    "\n",
    "\n",
    "class Info(BaseModel):\n",
    "    \"\"\"Information about a note.\"\"\"\n",
    "\n",
    "    category: Optional[str] = Field(\n",
    "        description=f\"Can be one of the following:\\n {category_prompt}\"\n",
    "    )\n",
    "    summary: Optional[str] = Field(\n",
    "        description=\"Concise one or two sentence summary of note's contents to be used for similarity search.\"\n",
    "    )\n",
    "    extract: Optional[str] = Field(\n",
    "        description=\"The essential concepts withing the note, used to link it to semantically similar ones.\"\n",
    "    )\n",
    "\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are an expert extraction algorithm. \"\n",
    "            \"Only extract relevant information from the text. \"\n",
    "            \"If you do not know the value of an attribute asked \"\n",
    "            \"to extract, return null for the attribute's value.\",\n",
    "        ),\n",
    "        (\"human\", \"{text}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "class NoteWithInfo(Note):\n",
    "    category: Optional[str]\n",
    "    summary: str\n",
    "    extract: Optional[str]\n",
    "\n",
    "    @classmethod\n",
    "    def from_note(\n",
    "        cls, note: Note, category: str, summary: str, extract: str\n",
    "    ) -> \"NoteWithInfo\":\n",
    "        return cls(\n",
    "            name=note.name,\n",
    "            frontmatter=note.frontmatter,\n",
    "            body=note.body,\n",
    "            relative_path=note.relative_path,\n",
    "            category=category,\n",
    "            summary=summary,\n",
    "            extract=extract,\n",
    "        )\n",
    "\n",
    "\n",
    "runnable = prompt | llm.with_structured_output(schema=Info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "persist_path.mkdir(exist_ok=True, parents=True)\n",
    "all_notes_path = persist_path.joinpath(\"all_notes.jsonl\")\n",
    "\n",
    "# 1. Load existing progress\n",
    "notes_with_infos = {}\n",
    "\n",
    "if all_notes_path.exists():\n",
    "    with all_notes_path.open(\"r\") as f:\n",
    "        for line in f.readlines():\n",
    "            note = NoteWithInfo.parse_raw(line)\n",
    "            notes_with_infos[note.relative_path] = note\n",
    "else:\n",
    "    with all_notes_path.open(\"w\"):\n",
    "        pass\n",
    "\n",
    "# 2. Process notes\n",
    "for note in tqdm(notes):\n",
    "    # Skip if already exists\n",
    "    if note.location in notes_with_infos:\n",
    "        continue\n",
    "\n",
    "    # Process and convert\n",
    "    response = runnable.invoke({\"text\": note.body})\n",
    "\n",
    "    note_with_info = NoteWithInfo.from_note(\n",
    "        note,\n",
    "        category=response.category,\n",
    "        summary=response.summary,\n",
    "        extract=response.extract,\n",
    "    )\n",
    "    notes_with_infos[note_with_info.relative_path] = note_with_info\n",
    "\n",
    "    # Save progress\n",
    "    with all_notes_path.open(\"a\") as f:\n",
    "        f.write(f\"{note_with_info.json()}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find related notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = []\n",
    "\n",
    "for note in notes_with_infos.values():\n",
    "    if note.extract is None:\n",
    "        continue\n",
    "    doc = Document(\n",
    "        page_content=note.extract,\n",
    "        metadata={\n",
    "            k: v for k, v in note.dict().items() if type(v) in [str, int, float, bool]\n",
    "        },\n",
    "    )\n",
    "    docs.append(doc)\n",
    "\n",
    "db = Chroma.from_documents(\n",
    "    docs,\n",
    "    OpenAIEmbeddings(model=\"text-embedding-ada-002\"),\n",
    "    persist_directory=\"notes_vectorstore_2\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = docs[77]\n",
    "print(doc.metadata[\"name\"])\n",
    "query = doc.page_content\n",
    "db.similarity_search(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RelevanceScore(BaseModel):\n",
    "    \"\"\"Information about a note.\"\"\"\n",
    "\n",
    "    is_relevant: Optional[bool] = Field(description=\"Whether two pieces of text are related or not.\")\n",
    "    reason: Optional[str] = Field(description=\"Reasoning behind the given score.\")\n",
    "\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are an expert scoring algorithm. \"\n",
    "            \"Rate whether two pieces of text provided to you are related. \",\n",
    "        ),\n",
    "        (\"human\", \"{text}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "runnable = prompt | llm.with_structured_output(schema=RelevanceScore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_related(note, db):\n",
    "    query = note.extract\n",
    "    related_docs = db.similarity_search(query)\n",
    "    related_names = [doc.metadata[\"name\"] for doc in related_docs]\n",
    "    return related_names"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "note_processor",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
